# NeuroCanvas: AI Art from Brainwaves

**Multiâ€‘Modal AI System | EEG Signals + Text â†’ Unique Art Generation**

---

## ğŸŒŸ Overview

NeuroCanvas is an end-to-end multi-modal AI project that fuses real EEG brainwave signals with natural-language prompts to generate unique AI artworks that visually represent mental state and imagination. The system combines EEG preprocessing, a cross-modal fusion network, and Stable Diffusion â€” all exposed via a real-time Gradio interface for demos and exploration.

---

## ğŸ§© Key Features

* **EEG Signal Processing** â€” Robust extraction and preprocessing of EEG features from real datasets.
* **Multi-Modal Fusion Model** â€” Learns alignment between brain-state embeddings and text embeddings.
* **Stable Diffusion Integration** â€” High-quality image generation conditioned on fused embeddings.
* **Custom Neural Network** â€” Lightweight networks (~500K parameters) tailored for EEG+text fusion.
* **Interactive Gradio UI** â€” Real-time controls, visualizations, and generation pipeline.
* **Deployment Ready** â€” Docker configs and multiple deployment pathways (Hugging Face Spaces, Cloud Run, SageMaker).
* **Well-documented & Tested** â€” Clear code organization, logging, and error handling.

---

## ğŸ§  System Architecture

```
EEG Signal  +  Text Prompt
      â”‚              â”‚
      â–¼              â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ EEGNet â”‚    â”‚ TextEncoderâ”‚
 â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚               â”‚
      â–¼               â–¼
     â””â”€â”€â”€â”€â”€â”€â–¶ Fusion Network â—€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
        ğŸ¨ Stable Diffusion
                  â”‚
                  â–¼
          Generated Artwork
```

---

## âš™ï¸ Tech Stack

**Programming:** Python, PyTorch

**Deep Learning:** Transformers, Stable Diffusion

**Data Handling:** NumPy, Pandas, scikit-learn

**Visualization:** Matplotlib (note: seaborn used only for exploratory plots)

**Interface:** Gradio

**Deployment:** Hugging Face Spaces, Google Cloud Run, AWS SageMaker, Heroku

---

## ğŸ“‚ Project Structure

```
neurocanvas/
â”œâ”€â”€ app.py                 # Main Gradio application entry point
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md             # Project documentation
â”œâ”€â”€ .env                 # Environment variables (not committed)
â”œâ”€â”€ .gitignore           # Git ignore rules
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py      # Configuration settings
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ loader.py    # Dataset loading & Kaggle integration
â”‚   â”‚   â””â”€â”€ processor.py # EEG preprocessing pipeline
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ fusion.py    # EEG-Text fusion model
â”‚   â”‚   â””â”€â”€ generator.py # Art generation pipeline
â”‚   â””â”€â”€ ui/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ interface.py # Gradio UI components
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Raw EEG data
â”‚   â”œâ”€â”€ processed/      # Processed features
â”‚   â””â”€â”€ models/         # Saved models
â””â”€â”€   Nuerocanvas.ipynb      # Jupyter notebooks for experimentation

---

## ğŸ“Š Model Performance & Metrics

* **Parameters:** ~500K
* **Training Dataset:** Public EEG datasets (example: Kaggle EEG sets)
* **Inference Time:** ~3â€“5 seconds per image (depends on hardware)
* **Validation:** Fusion metrics demonstrate strong alignment between brain-state and prompt semantics (report metric plots in `/results`)

---

## ğŸ§  Example Prompts & Settings

| Brain Activity Level | Art Prompt                                | Steps | Guidance |
| -------------------- | ----------------------------------------- | ----: | -------: |
| High (Alert)         | Neural networks glowing with electricity  |    30 |      7.5 |
| Medium (Relaxed)     | Peaceful zen garden in the mind           |    30 |      7.5 |
| Low (Drowsy)         | Dreamlike clouds of consciousness         |    30 |      7.5 |
| High (Alert)         | Cyberpunk brain interface with neon lines |    30 |      8.0 |
| Medium (Relaxed)     | Abstract thoughts flowing like water      |    30 |      7.0 |

> Tip: Map EEG-derived scalar features (e.g., alpha/beta ratios, engagement scores) to conditioning strength or style parameters for dynamic variation.

---

## ğŸš€ How to Run (Local)

1. Create virtual environment and install dependencies:

```bash
python -m venv .venv
source .venv/bin/activate   # or .venv\Scripts\activate on Windows
pip install -r requirements.txt
```

2. Prepare data (example):

```bash
python data/fetch_data.py
python data/preprocess.py
```

3. Start the Gradio demo:

```bash
python app.py
```

---

## ğŸ§­ Deployment Options

* **Hugging Face Spaces** â€” Easiest for portfolio demos; ideal for CPU/GPU-based web demos.
* **Google Cloud Run** â€” Containerized, autoscaling deployments.
* **AWS SageMaker** â€” For production model serving and monitoring.
* **Heroku** â€” Quick prototype hosting (less suited for GPU workloads).

---

## ğŸ“ˆ Future Enhancements

* Integrate real EEG hardware (Muse, OpenBCI) for live captures.
* Dynamic style transfer based on continuous brain-state trajectories.
* User gallery, sharing, and versioning of generated art.
* Mobile client for on-device viewing and lightweight generation.
* Video generation from EEG time-series sequences.

---

## ğŸ§‘â€ğŸ’» Interview Talking Points

* Architecture rationale: why fuse EEG with text and how alignment improves semantics.
* Data challenges: artifact removal, subject variability, label sparsity.
* Training details: loss functions, scheduling, multimodal contrastive or alignment objectives.
* Deployment considerations: latency, GPU vs CPU inference, user privacy for EEG data.
* Demo walkthrough: show preprocessing â†’ fusion â†’ Stable Diffusion pipeline live on Gradio.

---

## ğŸ§¾ Requirements

Install dependencies:

```bash
pip install -r requirements.txt
```

Run the app:

```bash
python app.py
```

---

## ğŸ§  About the Creator

DEMO : " https://drive.google.com/file/d/1GmkyCU0HdTKcqvbXvawgK4Rhx-OBEVF6/view?usp=drive_link "

Created by **[kamshetty varun]**, AI/ML Engineer passionate about brain-computer interfaces and creative AI systems.

---

â­ If you find this project inspiring, donâ€™t forget to star the repo!

---


